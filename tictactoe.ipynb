{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "tictactoe.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fatkhi/Neural-networks/blob/master/tictactoe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk733F9nZfve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copied from https://github.com/neilslater/game_playing_scripts\n",
        "\n",
        "'''\n",
        "   Copyright 2017 Neil Slater\n",
        "\n",
        "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "   you may not use this file except in compliance with the License.\n",
        "   You may obtain a copy of the License at\n",
        "\n",
        "       http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "   Unless required by applicable law or agreed to in writing, software\n",
        "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "   See the License for the specific language governing permissions and\n",
        "   limitations under the License.\n",
        "'''\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import csv\n",
        "import random\n",
        "from itertools import groupby\n",
        "\n",
        "class TicTacToeGame():\n",
        "    def __init__(self):\n",
        "        self.state = '         '\n",
        "        self.player = 'X'\n",
        "        self.winner = None\n",
        "\n",
        "    def allowed_moves(self):\n",
        "        states = []\n",
        "        for i in range(len(self.state)):\n",
        "            if self.state[i] == ' ':\n",
        "                states.append(self.state[:i] + self.player + self.state[i+1:])\n",
        "        return states\n",
        "\n",
        "    def make_move(self, next_state):\n",
        "        if self.winner:\n",
        "            raise(Exception(\"Game already completed, cannot make another move!\"))\n",
        "        if not self.__valid_move(next_state):\n",
        "            raise(Exception(\"Cannot make move {} to {} for player {}\".format(\n",
        "                    self.state, next_state, self.player)))\n",
        "\n",
        "        self.state = next_state\n",
        "        self.winner = self.predict_winner(self.state)\n",
        "        if self.winner:\n",
        "            self.player = None\n",
        "        elif self.player == 'X':\n",
        "            self.player = 'O'\n",
        "        else:\n",
        "            self.player = 'X'\n",
        "\n",
        "    def playable(self):\n",
        "        return ( (not self.winner) and any(self.allowed_moves()) )\n",
        "\n",
        "    def predict_winner(self, state):\n",
        "        lines = [(0,1,2), (3,4,5), (6,7,8), (0,3,6), (1,4,7), (2,5,8), (0,4,8), (2,4,6)]\n",
        "        winner = None\n",
        "        for line in lines:\n",
        "            line_state = state[line[0]] + state[line[1]] + state[line[2]]\n",
        "            if line_state == 'XXX':\n",
        "                winner = 'X'\n",
        "            elif line_state == 'OOO':\n",
        "                winner = 'O'\n",
        "        return winner\n",
        "\n",
        "    def __valid_move(self, next_state):\n",
        "        allowed_moves = self.allowed_moves()\n",
        "        if any(state == next_state for state in allowed_moves):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def print_board(self):\n",
        "        s = self.state\n",
        "        print('     {} | {} | {} '.format(s[0],s[1],s[2]))\n",
        "        print('    -----------')\n",
        "        print('     {} | {} | {} '.format(s[3],s[4],s[5]))\n",
        "        print('    -----------')\n",
        "        print('     {} | {} | {} '.format(s[6],s[7],s[8]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73rJFnfLGGa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(9, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 1)\n",
        "        self.optim = optim.SGD(self.parameters(), lr=.001)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = torch.tensor(x)\n",
        "        x = x.view(-1, 9)\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = torch.tanh(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    \n",
        "    def loss(self, output, target, **kwargs):\n",
        "        self._loss = F.mse_loss(output, target, **kwargs)\n",
        "        return self._loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL0yaL0aZfvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent():\n",
        "    def __init__(self, game_class, epsilon=0.1, player_mark='X', gamma=0.5):\n",
        "        self.net = Net()\n",
        "        self.NewGame = game_class\n",
        "        self.epsilon = epsilon\n",
        "        self.gamma = gamma\n",
        "        self.player_mark = player_mark\n",
        "    \n",
        "    def transform(self, move):\n",
        "        res = []\n",
        "        for char in move:\n",
        "            num = 0.\n",
        "            if char == \"X\":\n",
        "                num = 1.\n",
        "            if char == \"O\":\n",
        "                num = -1.\n",
        "            res.append(num)\n",
        "        return res\n",
        "\n",
        "    def learn_game(self, num_episodes=1000):\n",
        "        for episode in range(num_episodes):\n",
        "            self.learn_from_episode()\n",
        "\n",
        "    def learn_from_episode(self):\n",
        "        game = self.NewGame()\n",
        "        _, move = self.learn_select_move(game)\n",
        "        while move:\n",
        "            move = self.learn_from_move(game, move)\n",
        "\n",
        "    def learn_from_move(self, game, move):\n",
        "        game.make_move(move)\n",
        "        r = self.__reward(game)\n",
        "        target = r\n",
        "        selected_next_move = None\n",
        "        next_state_value = 0.0\n",
        "\n",
        "        if game.playable():\n",
        "            best_move, selected_next_move = self.learn_select_move(game)\n",
        "            with torch.no_grad():\n",
        "                next_state_value = self.net(self.transform(best_move))\n",
        "\n",
        "        target = torch.tensor(r).view(-1,1) + self.gamma * next_state_value\n",
        "\n",
        "        self.net.optim.zero_grad()\n",
        "        curr_value = self.net(self.transform(move))\n",
        "        loss = self.net.loss(curr_value, target)\n",
        "        loss.backward()\n",
        "        self.net.optim.step()\n",
        "\n",
        "        return selected_next_move\n",
        "\n",
        "    def learn_select_move(self, game):\n",
        "        with torch.no_grad():\n",
        "            moves_value = self.net([self.transform(m) for m in game.allowed_moves()])\n",
        "            if game.player == self.player_mark:\n",
        "                best_move = game.allowed_moves()[torch.argmax(moves_value)]\n",
        "            else:\n",
        "                best_move = game.allowed_moves()[torch.argmin(moves_value)]\n",
        "\n",
        "        selected_next_move = best_move\n",
        "        if random.random() < self.epsilon:\n",
        "            selected_next_move = random.choice(game.allowed_moves())\n",
        "\n",
        "        return (best_move, selected_next_move)\n",
        "\n",
        "    def play_select_move(self, game):\n",
        "        with torch.no_grad():\n",
        "            moves_value = self.net([self.transform(m) for m in game.allowed_moves()])\n",
        "            if game.player == self.player_mark:\n",
        "                return game.allowed_moves()[torch.argmax(moves_value)]\n",
        "            else:\n",
        "                return game.allowed_moves()[torch.argmin(moves_value)]\n",
        "\n",
        "    def demo_game(self, verbose=False):\n",
        "        game = self.NewGame()\n",
        "        t = 0\n",
        "        while game.playable():\n",
        "            if verbose:\n",
        "                print(\" \\nTurn {}\\n\".format(t))\n",
        "                game.print_board()\n",
        "            move = self.play_select_move(game)\n",
        "            game.make_move(move)\n",
        "            t += 1\n",
        "        if verbose:\n",
        "            print(\" \\nTurn {}\\n\".format(t))\n",
        "            game.print_board()\n",
        "        if game.winner:\n",
        "            if verbose:\n",
        "                print(\"\\n{} is the winner!\".format(game.winner))\n",
        "            return game.winner\n",
        "        else:\n",
        "            if verbose:\n",
        "                print(\"\\nIt's a draw!\")\n",
        "            return '-'\n",
        "\n",
        "    def random_move(self, game):\n",
        "        return random.choice(game.allowed_moves())\n",
        "\n",
        "    def random_game(self, agent_player='X', verbose=False):\n",
        "        game = self.NewGame()\n",
        "        t = 0\n",
        "        while game.playable():\n",
        "            move = None\n",
        "            if verbose:\n",
        "                print(\" \\nTurn {}\\n\".format(t))\n",
        "                game.print_board()\n",
        "            if game.player == agent_player:\n",
        "                move = self.play_select_move(game)\n",
        "            else:\n",
        "                move = self.random_move(game)\n",
        "\n",
        "            game.make_move(move)\n",
        "            t += 1\n",
        "        if verbose:\n",
        "            print(\" \\nTurn {}\\n\".format(t))\n",
        "            game.print_board()\n",
        "        if game.winner:\n",
        "            if verbose:\n",
        "                print(\"\\n{} is the winner!\".format(game.winner))\n",
        "            return game.winner\n",
        "        else:\n",
        "            if verbose:\n",
        "                print(\"\\nIt's a draw!\")\n",
        "            return '-'\n",
        "\n",
        "    def interactive_game(self, agent_player='X'):\n",
        "        game = self.NewGame()\n",
        "        t = 0\n",
        "        while game.playable():\n",
        "            print(\" \\nTurn {}\\n\".format(t))\n",
        "            game.print_board()\n",
        "            if game.player == agent_player:\n",
        "                move = self.play_select_move(game)\n",
        "                game.make_move(move)\n",
        "            else:\n",
        "                move = self.__request_human_move(game)\n",
        "                game.make_move(move)\n",
        "            t += 1\n",
        "\n",
        "        print(\" \\nTurn {}\\n\".format(t))\n",
        "        game.print_board()\n",
        "\n",
        "        if game.winner:\n",
        "            print(\"\\n{} is the winner!\".format(game.winner))\n",
        "            return game.winner\n",
        "        print(\"\\nIt's a draw!\")\n",
        "        return '-'\n",
        "\n",
        "    def __reward(self, game):\n",
        "        if game.winner == self.player_mark:\n",
        "            return 1.0\n",
        "        elif game.winner:\n",
        "            return -1.0\n",
        "        else:\n",
        "            return 0.0\n",
        "\n",
        "    def __request_human_move(self, game):\n",
        "        allowed_moves = [i+1 for i in range(9) if game.state[i] == ' ']\n",
        "        human_move = None\n",
        "        while not human_move:\n",
        "            idx = int(input('Choose move for {}, from {} : '.format(game.player, allowed_moves)))\n",
        "            if any([i==idx for i in allowed_moves]):\n",
        "                human_move = game.state[:idx-1] + game.player + game.state[idx:]\n",
        "        return human_move"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhwNyI0xRO0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def demo_game_stats(agent, agent_player='X'):\n",
        "    results = [agent.random_game(agent_player) for i in range(10000)]\n",
        "    game_stats = {k: results.count(k)/100 for k in ['X', 'O', '-']}\n",
        "    print(\"For {} percentage results: {}\".format(agent_player, game_stats))\n",
        "    return game_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awk-6O7MQgOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agent = Agent(TicTacToeGame, epsilon = 0.5, gamma = 0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qke6u2gFdVxj",
        "colab_type": "code",
        "outputId": "09ad05b9-477c-445c-cae3-74192fd26d17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "games_for_iteration = 1000\n",
        "for i in range(1, 1001):\n",
        "    agent.learn_game(games_for_iteration)\n",
        "    print('{} games learned: '.format(i * games_for_iteration))\n",
        "    print('Self play result:' )\n",
        "    print(agent.demo_game())\n",
        "    if demo_game_stats(agent)[\"O\"] == 0.0 and demo_game_stats(agent, agent_player=\"O\")[\"X\"] == 0.0:\n",
        "        break"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 games learned: \n",
            "Self play result:\n",
            "X\n",
            "For X percentage results: {'X': 89.94, 'O': 6.05, '-': 4.01}\n",
            "2000 games learned: \n",
            "Self play result:\n",
            "X\n",
            "For X percentage results: {'X': 80.63, 'O': 17.4, '-': 1.97}\n",
            "3000 games learned: \n",
            "Self play result:\n",
            "X\n",
            "For X percentage results: {'X': 90.44, 'O': 5.82, '-': 3.74}\n",
            "4000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 96.97, 'O': 1.3, '-': 1.73}\n",
            "5000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 94.17, 'O': 2.65, '-': 3.18}\n",
            "6000 games learned: \n",
            "Self play result:\n",
            "X\n",
            "For X percentage results: {'X': 95.91, 'O': 2.82, '-': 1.27}\n",
            "7000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 97.51, 'O': 0.0, '-': 2.49}\n",
            "For O percentage results: {'X': 8.01, 'O': 79.62, '-': 12.37}\n",
            "8000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.38, 'O': 0.0, '-': 1.62}\n",
            "For O percentage results: {'X': 8.33, 'O': 82.58, '-': 9.09}\n",
            "9000 games learned: \n",
            "Self play result:\n",
            "X\n",
            "For X percentage results: {'X': 98.67, 'O': 0.0, '-': 1.33}\n",
            "For O percentage results: {'X': 10.01, 'O': 82.47, '-': 7.52}\n",
            "10000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.25, 'O': 0.0, '-': 1.75}\n",
            "For O percentage results: {'X': 8.0, 'O': 82.24, '-': 9.76}\n",
            "11000 games learned: \n",
            "Self play result:\n",
            "X\n",
            "For X percentage results: {'X': 94.3, 'O': 0.83, '-': 4.87}\n",
            "12000 games learned: \n",
            "Self play result:\n",
            "X\n",
            "For X percentage results: {'X': 97.76, 'O': 0.0, '-': 2.24}\n",
            "For O percentage results: {'X': 4.21, 'O': 87.82, '-': 7.97}\n",
            "13000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 96.81, 'O': 0.63, '-': 2.56}\n",
            "14000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 97.83, 'O': 0.0, '-': 2.17}\n",
            "For O percentage results: {'X': 2.62, 'O': 85.86, '-': 11.52}\n",
            "15000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.63, 'O': 0.0, '-': 1.37}\n",
            "For O percentage results: {'X': 1.28, 'O': 89.49, '-': 9.23}\n",
            "16000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.27, 'O': 0.0, '-': 1.73}\n",
            "For O percentage results: {'X': 3.9, 'O': 87.82, '-': 8.28}\n",
            "17000 games learned: \n",
            "Self play result:\n",
            "X\n",
            "For X percentage results: {'X': 98.46, 'O': 0.0, '-': 1.54}\n",
            "For O percentage results: {'X': 3.45, 'O': 86.02, '-': 10.53}\n",
            "18000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.42, 'O': 0.0, '-': 1.58}\n",
            "For O percentage results: {'X': 0.47, 'O': 90.26, '-': 9.27}\n",
            "19000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.97, 'O': 0.0, '-': 1.03}\n",
            "For O percentage results: {'X': 0.84, 'O': 90.07, '-': 9.09}\n",
            "20000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.68, 'O': 0.0, '-': 1.32}\n",
            "For O percentage results: {'X': 3.65, 'O': 87.33, '-': 9.02}\n",
            "21000 games learned: \n",
            "Self play result:\n",
            "X\n",
            "For X percentage results: {'X': 98.66, 'O': 0.0, '-': 1.34}\n",
            "For O percentage results: {'X': 1.8, 'O': 90.38, '-': 7.82}\n",
            "22000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.16, 'O': 0.0, '-': 1.84}\n",
            "For O percentage results: {'X': 0.97, 'O': 89.32, '-': 9.71}\n",
            "23000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 99.2, 'O': 0.0, '-': 0.8}\n",
            "For O percentage results: {'X': 0.64, 'O': 90.98, '-': 8.38}\n",
            "24000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.91, 'O': 0.0, '-': 1.09}\n",
            "For O percentage results: {'X': 0.19, 'O': 91.17, '-': 8.64}\n",
            "25000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.58, 'O': 0.0, '-': 1.42}\n",
            "For O percentage results: {'X': 2.18, 'O': 90.36, '-': 7.46}\n",
            "26000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.74, 'O': 0.0, '-': 1.26}\n",
            "For O percentage results: {'X': 1.91, 'O': 90.37, '-': 7.72}\n",
            "27000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.9, 'O': 0.0, '-': 1.1}\n",
            "For O percentage results: {'X': 0.26, 'O': 90.68, '-': 9.06}\n",
            "28000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.34, 'O': 0.0, '-': 1.66}\n",
            "For O percentage results: {'X': 5.47, 'O': 86.15, '-': 8.38}\n",
            "29000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.75, 'O': 0.0, '-': 1.25}\n",
            "For O percentage results: {'X': 0.96, 'O': 89.91, '-': 9.13}\n",
            "30000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.14, 'O': 0.0, '-': 1.86}\n",
            "For O percentage results: {'X': 0.55, 'O': 90.84, '-': 8.61}\n",
            "31000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.92, 'O': 0.0, '-': 1.08}\n",
            "For O percentage results: {'X': 0.4, 'O': 91.46, '-': 8.14}\n",
            "32000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.69, 'O': 0.0, '-': 1.31}\n",
            "For O percentage results: {'X': 1.18, 'O': 89.93, '-': 8.89}\n",
            "33000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.93, 'O': 0.0, '-': 1.07}\n",
            "For O percentage results: {'X': 0.37, 'O': 91.02, '-': 8.61}\n",
            "34000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.98, 'O': 0.0, '-': 1.02}\n",
            "For O percentage results: {'X': 0.11, 'O': 90.85, '-': 9.04}\n",
            "35000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.98, 'O': 0.0, '-': 1.02}\n",
            "For O percentage results: {'X': 0.58, 'O': 91.07, '-': 8.35}\n",
            "36000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.96, 'O': 0.0, '-': 1.04}\n",
            "For O percentage results: {'X': 0.41, 'O': 92.01, '-': 7.58}\n",
            "37000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.69, 'O': 0.0, '-': 1.31}\n",
            "For O percentage results: {'X': 1.0, 'O': 91.36, '-': 7.64}\n",
            "38000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.38, 'O': 0.0, '-': 1.62}\n",
            "For O percentage results: {'X': 3.21, 'O': 87.79, '-': 9.0}\n",
            "39000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.9, 'O': 0.0, '-': 1.1}\n",
            "For O percentage results: {'X': 0.58, 'O': 90.91, '-': 8.51}\n",
            "40000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.79, 'O': 0.0, '-': 1.21}\n",
            "For O percentage results: {'X': 0.45, 'O': 88.83, '-': 10.72}\n",
            "41000 games learned: \n",
            "Self play result:\n",
            "-\n",
            "For X percentage results: {'X': 98.89, 'O': 0.0, '-': 1.11}\n",
            "For O percentage results: {'X': 0.0, 'O': 90.14, '-': 9.86}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmahG5mFzPPy",
        "colab_type": "code",
        "outputId": "7811af57-9046-4251-ddc6-c5691e8dbec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "agent.demo_game(True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \n",
            "Turn 0\n",
            "\n",
            "       |   |   \n",
            "    -----------\n",
            "       |   |   \n",
            "    -----------\n",
            "       |   |   \n",
            " \n",
            "Turn 1\n",
            "\n",
            "       |   |   \n",
            "    -----------\n",
            "       | X |   \n",
            "    -----------\n",
            "       |   |   \n",
            " \n",
            "Turn 2\n",
            "\n",
            "       |   |   \n",
            "    -----------\n",
            "       | X |   \n",
            "    -----------\n",
            "       |   | O \n",
            " \n",
            "Turn 3\n",
            "\n",
            "       |   |   \n",
            "    -----------\n",
            "       | X |   \n",
            "    -----------\n",
            "       | X | O \n",
            " \n",
            "Turn 4\n",
            "\n",
            "       | O |   \n",
            "    -----------\n",
            "       | X |   \n",
            "    -----------\n",
            "       | X | O \n",
            " \n",
            "Turn 5\n",
            "\n",
            "       | O | X \n",
            "    -----------\n",
            "       | X |   \n",
            "    -----------\n",
            "       | X | O \n",
            " \n",
            "Turn 6\n",
            "\n",
            "       | O | X \n",
            "    -----------\n",
            "       | X |   \n",
            "    -----------\n",
            "     O | X | O \n",
            " \n",
            "Turn 7\n",
            "\n",
            "       | O | X \n",
            "    -----------\n",
            "     X | X |   \n",
            "    -----------\n",
            "     O | X | O \n",
            " \n",
            "Turn 8\n",
            "\n",
            "       | O | X \n",
            "    -----------\n",
            "     X | X | O \n",
            "    -----------\n",
            "     O | X | O \n",
            " \n",
            "Turn 9\n",
            "\n",
            "     X | O | X \n",
            "    -----------\n",
            "     X | X | O \n",
            "    -----------\n",
            "     O | X | O \n",
            "\n",
            "It's a draw!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'-'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    }
  ]
}